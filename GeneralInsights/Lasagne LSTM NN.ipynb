{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing csv input...\n",
      "Detected csv comma delimiter...\n",
      "Garbage removal and Deduping with parameter: True\n",
      "Removed 88 duplicate comments."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:consider setting layer size to a multiple of 4 for greater performance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import os, sys, inspect\n",
    "import numpy as np\n",
    "import math\n",
    "from Preprocessing.loadCleanly import sheets as sh\n",
    "from gensim import corpora\n",
    "from textmining import simple_tokenize_remove_stopwords\n",
    "import lasagne\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import copy\n",
    "# Setting the data directories. \n",
    "# Preoprocessing.loadCleanly is what is what was being used already\n",
    "_data_directory ='D:\\GeneralInsights\\Naytev\\data'\n",
    "_data_file = 'Annotated_Comments_for_Naytev_Facebook.csv'\n",
    "_text_col = 0\n",
    "_label_col = 5\n",
    "header, rows = sh.get_spreadsheet_rows(os.path.join(_data_directory, _data_file), _text_col, dedupe=True)\n",
    "\n",
    "#make the sentences and classes list. \n",
    "#Sentences contains sentences\n",
    "#Classes contains the sentiment\n",
    "sentences = [str(S[_text_col]) for S in rows]\n",
    "classes   = [str(S[_label_col]) for S in rows]\n",
    "\n",
    "#Tokeninzethe Sentence List\n",
    "texts = [simple_tokenize_remove_stopwords(sentence) for sentence in sentences]\n",
    "model = Word2Vec(texts, size=10, window=5, min_count=0, workers=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Construct the Sentiment LSTM Layer by Layer. The output of this will be a Lasagne Layer Object\n",
    "def MakeSentimentLSTM(input_var):\n",
    "    \n",
    "    #batch size = 10 , 15 is the maximum sentence length, 10 is the word vector dimension\n",
    "    l_in = lasagne.layers.InputLayer(shape=(10,15,10),\n",
    "                                         input_var=input_var)\n",
    "    l_lstm = lasagne.layers.LSTMLayer(l_in, num_units=10,peepholes=False)\n",
    "    \n",
    "    #l_pool = lasagne.layers.GlobalPoolLayer(l_lstm) # Not including the pooling layer for now\n",
    "\n",
    "    l_shp =lasagne.layers.ReshapeLayer(l_in, (10*15, 10)) # the LSTM Layer must be reshaped See the example in the Docs\n",
    "    \n",
    "    l_out = lasagne.layers.DenseLayer(l_shp, num_units=10)\n",
    "    \n",
    "    return l_out\n",
    "\n",
    "\n",
    "# Function to create random minibatches\n",
    "# This won't be called until the LSTM is\n",
    "# all Wired\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        \n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n",
    "\n",
    "# This converts the classes list to a list of digits\n",
    "# Neural Networks tend to be better at classifying numbers\n",
    "def ESentimentToDigits(Texts):\n",
    "    Sentiments = []\n",
    "    for Sentiment in Texts:\n",
    "        if Sentiment == 'Positive':\n",
    "            Sentiments.append(1)\n",
    "        else:\n",
    "            Sentiments.append(0)\n",
    "    return np.array(Sentiments)\n",
    "\n",
    "# The next 3 functions are set to pad a sentence with sequences of zeros if it is less than the maximum sentence length\n",
    "# This is so the corpus has sequences that are all the same length\n",
    "\n",
    "def PaddedZeros(InValue):\n",
    "    return np.array([[0]*10]*InValue)\n",
    "\n",
    "def GetMaxSentenceLength(InCorpus):\n",
    "    MaxLength = 0\n",
    "    for sentence in InCorpus:\n",
    "        if len(sentence) > MaxLength:\n",
    "            MaxLength = len(sentence)\n",
    "    print MaxLength\n",
    "    \n",
    "def PadCorpus(InCorpus):\n",
    "    MaxLength = GetMaxSentenceLength(InCorpus)\n",
    "    Texts = []\n",
    "    for sentence in InCorpus:\n",
    "        SentenceOne = sentence+PaddedZeros(15-len(sentence)).tolist()\n",
    "        Texts.append(SentenceOne)\n",
    "    return Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Prepare Theano variables for inputs and targets\n",
    "input_var = T.tensor3('inputs')\n",
    "target_var = T.ivector('targets')\n",
    "# Create neural network model\n",
    "network = MakeSentimentLSTM(input_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ellmi_000\\Anaconda\\lib\\site-packages\\theano\\scan_module\\scan.py:1019: Warning: In the strict mode, all neccessary shared variables must be passed as a part of non_sequences\n",
      "  'must be passed as a part of non_sequences', Warning)\n"
     ]
    }
   ],
   "source": [
    "# get the output. This is a 1d layer as per the shape of the output DenseLayer\n",
    "prediction = lasagne.layers.get_output(network)\n",
    "\n",
    "# From the output and the known output, compute the loss function. \n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "loss = loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Collect up all of the shared variables\n",
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "\n",
    "# Feed the Loss Function Error and the shared variables into the update function\n",
    "# This can be adadelta, Stoachastc Gradient Descent, etc. etc. or whatever you want\n",
    "# But this is where the weights are updated \n",
    "updates = lasagne.updates.adadelta(\n",
    "        loss, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ellmi_000\\Anaconda\\lib\\site-packages\\theano\\scan_module\\scan_perform_ext.py:135: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility\n",
      "  from scan_perform.scan_perform import *\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Wire up the training function to the training variables\n",
    "# This inputs to this are empty theano variables not actual data\n",
    "train_fn = theano.function([input_var, target_var], loss, updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# Here is where I make the training data\n",
    "\n",
    "\n",
    "# PadCorpus with zeroes \n",
    "# Also convert it to a numpy array\n",
    "\n",
    "D = [[model[word].tolist() for word in sentence] for sentence in texts]\n",
    "Texts = PadCorpus(D)\n",
    "TextNP = np.array(Texts) \n",
    "\n",
    "# Make a numpy Results array from the array of sentiment\n",
    "ResultsArray = ESentimentToDigits(classes)\n",
    "\n",
    "# Create the minibatch\n",
    "# For testing I'm only doing one\n",
    "TextBatch = TextNP[0:10]\n",
    "ResultsBatch = ResultsArray[0:10]\n",
    "\n",
    "#Print Just because\n",
    "print TextBatch.shape\n",
    "print ResultsBatch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for axis 0 with size 10\nApply node that caused the error: CrossentropyCategorical1Hot(Elemwise{Composite{(i0 * (Abs(i1) + i2 + i3))}}[(0, 2)].0, targets)\nToposort index: 220\nInputs types: [TensorType(float64, matrix), TensorType(int32, vector)]\nInputs shapes: [(150L, 10L), (10L,)]\nInputs strides: [(80L, 8L), (4L,)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[Sum{acc_dtype=float64}(CrossentropyCategorical1Hot.0), Shape_i{0}(CrossentropyCategorical1Hot.0)]]\n\nBacktrace when the node is created:\n  File \"C:\\Users\\ellmi_000\\Anaconda\\lib\\site-packages\\lasagne\\objectives.py\", line 129, in categorical_crossentropy\n    return theano.tensor.nnet.categorical_crossentropy(predictions, targets)\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-92ebd3682d8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Notice this is where the actual data is fed into the network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Figure this function out and your good\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrain_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTextBatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mResultsBatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\ellmi_000\\Anaconda\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    616\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthunks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m                         storage_map=self.fn.storage_map)\n\u001b[0m\u001b[0;32m    619\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                     \u001b[1;31m# For the c linker We don't have access from\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ellmi_000\\Anaconda\\lib\\site-packages\\theano\\gof\\link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    295\u001b[0m     exc_value = exc_type(str(exc_value) + detailed_err_msg +\n\u001b[0;32m    296\u001b[0m                          '\\n' + '\\n'.join(hints))\n\u001b[1;32m--> 297\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ellmi_000\\Anaconda\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ellmi_000\\Anaconda\\lib\\site-packages\\theano\\gof\\op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    759\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    762\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ellmi_000\\Anaconda\\lib\\site-packages\\theano\\tensor\\nnet\\nnet.pyc\u001b[0m in \u001b[0;36mperform\u001b[1;34m(self, node, inp, out)\u001b[0m\n\u001b[0;32m   1306\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoding\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1308\u001b[1;33m             \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoding\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_of_n\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1309\u001b[0m         \u001b[0my_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 10 is out of bounds for axis 0 with size 10\nApply node that caused the error: CrossentropyCategorical1Hot(Elemwise{Composite{(i0 * (Abs(i1) + i2 + i3))}}[(0, 2)].0, targets)\nToposort index: 220\nInputs types: [TensorType(float64, matrix), TensorType(int32, vector)]\nInputs shapes: [(150L, 10L), (10L,)]\nInputs strides: [(80L, 8L), (4L,)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[Sum{acc_dtype=float64}(CrossentropyCategorical1Hot.0), Shape_i{0}(CrossentropyCategorical1Hot.0)]]\n\nBacktrace when the node is created:\n  File \"C:\\Users\\ellmi_000\\Anaconda\\lib\\site-packages\\lasagne\\objectives.py\", line 129, in categorical_crossentropy\n    return theano.tensor.nnet.categorical_crossentropy(predictions, targets)\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the network\n",
    "# Notice this is where the actual data is fed into the network\n",
    "# Figure this function out and you are good\n",
    "train_fn(TextBatch,ResultsBatch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
